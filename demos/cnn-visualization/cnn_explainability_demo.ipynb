{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN Explainability Demo\n",
    "\n",
    "This notebook demonstrates three key techniques for understanding what Convolutional Neural Networks learn:\n",
    "\n",
    "1. **Filter Visualizations**: See what patterns individual filters detect\n",
    "2. **Activation Maximization**: Generate images that maximally activate specific filters\n",
    "3. **Class Activation Maps (Grad-CAM)**: Visualize which input regions drive predictions\n",
    "\n",
    "We'll use a simple 2-layer CNN trained on either MNIST or Fashion-MNIST to keep things interpretable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "\n",
    "Choose your dataset and training parameters here."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-29T13:53:45.466594Z",
     "start_time": "2025-10-29T13:53:45.463834Z"
    }
   },
   "source": [
    "# Dataset selection - change this to 'fashion_mnist' to switch datasets\n",
    "DATASET = 'mnist'  # Options: 'mnist' or 'fashion_mnist'\n",
    "\n",
    "# Training parameters\n",
    "TRAIN_NEW_MODEL = False  # Set to True to train from scratch, False to load pre-trained\n",
    "EPOCHS = 5\n",
    "BATCH_SIZE = 128\n",
    "LEARNING_RATE = 0.001\n",
    "\n",
    "# Model will be saved/loaded from:\n",
    "MODEL_PATH = f'saved_models/{DATASET}_simple_cnn.h5'\n",
    "\n",
    "print(f\"Configuration: {DATASET.upper()} dataset\")\n",
    "print(f\"Model path: {MODEL_PATH}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration: MNIST dataset\n",
      "Model path: saved_models/mnist_simple_cnn.h5\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and Setup"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-29T13:53:57.842941Z",
     "start_time": "2025-10-29T13:53:45.508088Z"
    }
   },
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.datasets import mnist, fashion_mnist\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "import os\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# Check TensorFlow version and GPU availability\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"GPU available: {len(tf.config.list_physical_devices('GPU')) > 0}\")\n",
    "\n",
    "# Class labels for visualization\n",
    "if DATASET == 'mnist':\n",
    "    CLASS_NAMES = [str(i) for i in range(10)]\n",
    "else:  # fashion_mnist\n",
    "    CLASS_NAMES = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "                   'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.20.0\n",
      "GPU available: False\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-29T13:54:01.406287Z",
     "start_time": "2025-10-29T13:54:01.143790Z"
    }
   },
   "source": [
    "# Load dataset\n",
    "if DATASET == 'mnist':\n",
    "    (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "else:  # fashion_mnist\n",
    "    (x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
    "\n",
    "# Preprocess data\n",
    "x_train = x_train.reshape(-1, 28, 28, 1).astype('float32') / 255.0\n",
    "x_test = x_test.reshape(-1, 28, 28, 1).astype('float32') / 255.0\n",
    "\n",
    "# Normalize to [-1, 1] range\n",
    "x_train = (x_train - 0.5) * 2\n",
    "x_test = (x_test - 0.5) * 2\n",
    "\n",
    "print(f\"Loaded {DATASET}: {len(x_train)} training samples, {len(x_test)} test samples\")\n",
    "print(f\"Image shape: {x_train.shape[1:]}\")\n",
    "print(f\"Value range: [{x_train.min():.2f}, {x_train.max():.2f}]\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded mnist: 60000 training samples, 10000 test samples\n",
      "Image shape: (28, 28, 1)\n",
      "Value range: [-1.00, 1.00]\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Simple CNN Architecture\n",
    "\n",
    "We use a deliberately simple architecture:\n",
    "- **Conv Layer 1**: 8 filters, 3x3 kernel\n",
    "- **Conv Layer 2**: 8 filters, 3x3 kernel\n",
    "- **Fully Connected**: Output layer\n",
    "\n",
    "This small architecture makes it easier to visualize and understand what each filter learns."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-29T13:54:01.443124Z",
     "start_time": "2025-10-29T13:54:01.411121Z"
    }
   },
   "source": [
    "def create_simple_cnn():\n",
    "    \"\"\"Create a simple 2-layer CNN for visualization.\"\"\"\n",
    "    model = models.Sequential([\n",
    "        # First convolutional layer: 8 filters, 3x3 kernel\n",
    "        layers.Conv2D(8, (3, 3), activation='relu', padding='same', \n",
    "                     input_shape=(28, 28, 1), name='conv1'),\n",
    "        layers.MaxPooling2D((2, 2), name='pool1'),  # 28x28 -> 14x14\n",
    "        \n",
    "        # Second convolutional layer: 8 filters, 3x3 kernel\n",
    "        layers.Conv2D(8, (3, 3), activation='relu', padding='same', name='conv2'),\n",
    "        layers.MaxPooling2D((2, 2), name='pool2'),  # 14x14 -> 7x7\n",
    "        \n",
    "        # Fully connected layer\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(10, name='output')\n",
    "    ])\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Create model\n",
    "model = create_simple_cnn()\n",
    "model.summary()\n",
    "\n",
    "# Compile model\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=LEARNING_RATE),\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=['accuracy']\n",
    ")"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ssogden/repos/classes/CST463-golden/.venv/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1mModel: \"sequential\"\u001B[0m\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001B[1m \u001B[0m\u001B[1mLayer (type)                   \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mOutput Shape          \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1m      Param #\u001B[0m\u001B[1m \u001B[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1 (\u001B[38;5;33mConv2D\u001B[0m)                  │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m28\u001B[0m, \u001B[38;5;34m28\u001B[0m, \u001B[38;5;34m8\u001B[0m)      │            \u001B[38;5;34m80\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ pool1 (\u001B[38;5;33mMaxPooling2D\u001B[0m)            │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m14\u001B[0m, \u001B[38;5;34m14\u001B[0m, \u001B[38;5;34m8\u001B[0m)      │             \u001B[38;5;34m0\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2 (\u001B[38;5;33mConv2D\u001B[0m)                  │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m14\u001B[0m, \u001B[38;5;34m14\u001B[0m, \u001B[38;5;34m8\u001B[0m)      │           \u001B[38;5;34m584\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ pool2 (\u001B[38;5;33mMaxPooling2D\u001B[0m)            │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m7\u001B[0m, \u001B[38;5;34m7\u001B[0m, \u001B[38;5;34m8\u001B[0m)        │             \u001B[38;5;34m0\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001B[38;5;33mFlatten\u001B[0m)               │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m392\u001B[0m)            │             \u001B[38;5;34m0\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ output (\u001B[38;5;33mDense\u001B[0m)                  │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m10\u001B[0m)             │         \u001B[38;5;34m3,930\u001B[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)      │            <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ pool1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)      │           <span style=\"color: #00af00; text-decoration-color: #00af00\">584</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ pool2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">392</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">3,930</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Total params: \u001B[0m\u001B[38;5;34m4,594\u001B[0m (17.95 KB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,594</span> (17.95 KB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Trainable params: \u001B[0m\u001B[38;5;34m4,594\u001B[0m (17.95 KB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,594</span> (17.95 KB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Non-trainable params: \u001B[0m\u001B[38;5;34m0\u001B[0m (0.00 B)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training (or Load Pre-trained Model)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-29T13:54:01.476658Z",
     "start_time": "2025-10-29T13:54:01.473483Z"
    }
   },
   "source": [
    "# Train or load model\n",
    "if TRAIN_NEW_MODEL:\n",
    "    print(\"Training new model...\")\n",
    "    \n",
    "    history = model.fit(\n",
    "        x_train, y_train,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        epochs=EPOCHS,\n",
    "        validation_data=(x_test, y_test),\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    # Evaluate final accuracy\n",
    "    test_loss, test_acc = model.evaluate(x_test, y_test, verbose=0)\n",
    "    print(f\"\\nFinal test accuracy: {test_acc*100:.2f}%\")\n",
    "    \n",
    "    # Save the trained model\n",
    "    os.makedirs('saved_models', exist_ok=True)\n",
    "    model.save(MODEL_PATH)\n",
    "    print(f\"Model saved to {MODEL_PATH}\")\n",
    "    \n",
    "else:\n",
    "    if os.path.exists(MODEL_PATH):\n",
    "        print(f\"Loading pre-trained model from {MODEL_PATH}\")\n",
    "        model = keras.models.load_model(MODEL_PATH)\n",
    "        \n",
    "        # Evaluate to show performance\n",
    "        test_loss, test_acc = model.evaluate(x_test, y_test, verbose=0)\n",
    "        print(f\"Model loaded successfully!\")\n",
    "        print(f\"Test accuracy: {test_acc*100:.2f}%\")\n",
    "    else:\n",
    "        print(f\"No pre-trained model found at {MODEL_PATH}\")\n",
    "        print(\"Set TRAIN_NEW_MODEL = True to train a new model\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No pre-trained model found at saved_models/mnist_simple_cnn.h5\n",
      "Set TRAIN_NEW_MODEL = True to train a new model\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Method 1: Filter Visualizations\n",
    "\n",
    "We'll visualize what patterns the convolutional filters learn in two ways:\n",
    "1. **Filter weights**: The raw learned kernels\n",
    "2. **Feature maps**: What the filters activate on when shown real images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1: Visualize Filter Weights (Raw Values + Heatmaps)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-29T13:54:02.042284Z",
     "start_time": "2025-10-29T13:54:01.496570Z"
    }
   },
   "source": [
    "def visualize_conv_filters(model, layer_name):\n",
    "    \"\"\"\n",
    "    Visualize the learned filters of a convolutional layer.\n",
    "    Shows both raw float values and heatmap visualizations.\n",
    "    \"\"\"\n",
    "    # Get the layer\n",
    "    layer = model.get_layer(layer_name)\n",
    "    \n",
    "    # Get filter weights: shape is (height, width, in_channels, out_channels)\n",
    "    weights = layer.get_weights()[0]  # [0] is weights, [1] is biases\n",
    "    num_filters = weights.shape[3]\n",
    "    in_channels = weights.shape[2]\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"{layer_name.upper()} - Filter Weights\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"Shape: {weights.shape} (height, width, in_channels, filters)\\n\")\n",
    "    \n",
    "    # Print raw values for first filter as example\n",
    "    print(f\"Raw weight values for Filter 0, Channel 0:\")\n",
    "    print(weights[:, :, 0, 0])\n",
    "    print(f\"\\nMin: {weights[:, :, 0, 0].min():.4f}, Max: {weights[:, :, 0, 0].max():.4f}\\n\")\n",
    "    \n",
    "    # Visualize all filters\n",
    "    fig, axes = plt.subplots(in_channels, num_filters, figsize=(num_filters * 1.5, in_channels * 1.5))\n",
    "    if in_channels == 1:\n",
    "        axes = axes.reshape(1, -1)\n",
    "    \n",
    "    for i in range(in_channels):\n",
    "        for j in range(num_filters):\n",
    "            ax = axes[i, j] if in_channels > 1 else axes[0, j]\n",
    "            \n",
    "            # Get filter weights for this channel and filter\n",
    "            w = weights[:, :, i, j]\n",
    "            \n",
    "            # Normalize for visualization\n",
    "            im = ax.imshow(w, cmap='RdBu', vmin=-abs(w).max(), vmax=abs(w).max())\n",
    "            \n",
    "            if i == 0:\n",
    "                ax.set_title(f'Filter {j}', fontsize=10)\n",
    "            if j == 0:\n",
    "                ax.set_ylabel(f'In Ch {i}', fontsize=10)\n",
    "            ax.axis('off')\n",
    "    \n",
    "    plt.suptitle(f'{layer_name.upper()} - Learned Filters (red=positive, blue=negative)', fontsize=12)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Visualize both convolutional layers\n",
    "visualize_conv_filters(model, 'conv1')\n",
    "visualize_conv_filters(model, 'conv2')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "CONV1 - Filter Weights\n",
      "============================================================\n",
      "Shape: (3, 3, 1, 8) (height, width, in_channels, filters)\n",
      "\n",
      "Raw weight values for Filter 0, Channel 0:\n",
      "[[ 0.1867908   0.22268608  0.00485638]\n",
      " [-0.01390657 -0.24409306 -0.01571438]\n",
      " [ 0.2610929   0.03707036 -0.22625725]]\n",
      "\n",
      "Min: -0.2441, Max: 0.2611\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x150 with 8 Axes>"
      ],
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABGwAAACYCAYAAACxvH9AAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjUsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvWftoOwAAAAlwSFlzAAAPYQAAD2EBqD+naQAAJCxJREFUeJzt3Qm8TeX+x/HnZMhUSANKlIgkmaIoiVKGkCElY/NVl+ridtN0RcUNDUpKGrjpSkLdphvuFSUilAwJXZmSUhmT9X99n/ta57/2Pnufca99nrPP5/167XL2Xmc9a3jWOvv5rd/zPGme53kGAAAAAAAAzjgqvzcAAAAAAAAAkQjYAAAAAAAAOIaADQAAAAAAgGMI2AAAAAAAADiGgA0AAAAAAIBjCNgAAAAAAAA4hoANAAAAAACAYwjYAAAAAAAAOIaADQAAAAAAgGMI2AAAkEQvvviiSUtLM5s2bcrTeubPn2/Xo//7+vbta6pVq2YKilGjRplatWqZI0eOFJjjnl8eeOABu/0FbV+1DdqWv/3tbwndR+RMMupEjx49TPfu3UNbPwAURgRsACDBNmzYYG6++WZz+umnmxIlSphjjz3WNGvWzDz++ONm//79Ecv+9ttv5oknnjCNGzc2xxxzjClTpoz9t97TZ9HUGNeX7ttvvz1uA/7111+3P1955ZWmVKlS5pdffom7rT179jTFixc3P/zwg/35tddeM9ddd52pUaOGXdfFF19swqL133bbbaGtv6DzG6+xXhMmTMjWOvbt22fXEwzquOLnn382jz76qBk6dKg56ii+juTGyJEjzZtvvpnfmwGH5Ged0LU8Y8YMs2LFinwpHwBSEd+QACCB3n77bVO3bl3zj3/8w3To0ME8+eST5uGHHzannnqqGTx4sBk4cGD6snv37jWXXnqpfa9ixYrmkUceMaNHjzaVK1e27+kzLRPLc889Z7Zu3ZrptigYowDRzJkz4zbmZ82aZS6//HJToUIF+94zzzxj36tSpYopX758no4FEkPn5JVXXol4tWrVylx00UX2/Or/8egcP/jgg04GbF544QVz+PBhc8011+T3phQIw4YNyxDwjdc479Wrl122atWqSdxCuCA/60T9+vVNo0aNzGOPPRZaGQBQ2BTN7w0AgFSxceNGmxKuL8Rz5841lSpVSv9swIAB5uuvv7YBHd+dd95p/v3vf9ugTjDT5NZbbzXjx4+37/3pT3+yDfagOnXqmLVr19oAjzJx4lGGjbJ2/v73v5vevXtn+FyBGQWEFNjxKRhw8skn24yHs88+2xQGCmooE8lVXbt2Nccff3zMz5TBlR9Ub0qXLp2ndUyePNnW0az2QUEddZlSJlhhVrRoUfvKjiJFitgXkOw6oS5R999/v3n66adtxigAIG/IsAGABI7H8euvv5pJkyZFBGt8Z5xxRnqGzZYtW+xyl1xyScxuQQrwtGzZ0jz//PN22ehuUQrAZJVlU7JkSXPVVVeZDz/80OzcuTPD5wrkKKCjRrNPmTUudU9RQ33cuHE2SKWG/UknnWS7m/34448Zgk/t2rWz2UlHH320qV69uhk+fLj5/fffI5ZTFy8Foj777DObmaJAzV/+8peIcTYmTpxof1/rUfe0JUuWZNiuNWvW2EDKcccdZ7dLT5Vnz56dYbkvv/zSnmOdi1NOOcU89NBDCRuvJdYYNkHapxNOOMH+W1k2fncqdZHKyX74Y18ouPiHP/zBnHjiiXZfRN3tBg0aZOukjpc+U2bYsmXLsgxurly50rRu3TrDNvvnQefdPw+rV6/O9vaGfdyD3fmmTp1qzjzzTLstDRs2NP/5z38yLLt8+XJzxRVX2K6RasAqO+qTTz6JWEbdH3WO1BVR61LGW/Pmzc0HH3wQd3wX/VuBs5deein93GoMo1jjlbRv39520Yzl/PPPt8cxaMqUKXZ/dPx0rBWI/u9//5vHo2bM2LFjbUBb623RooX54osvMl3erw/an2jRdVm+++47079/f3ufUL3RfUOZXIngH9OFCxfaYLuuLQUtO3fubL7//vsMy7/zzjvmwgsvtMvoPqv7k+pltOnTp5uzzjrLnnfdm5QRGWssKl0TF1xwga0bOn46P373V5fqhJ8ZGqy7AIDcI8MGABJkzpw59guwvlRnRV/mFUyIlfni02fz5s0z7777rrnhhhsiPrvnnnvMyy+/nGWWjbJn9OVdXbSCgaHdu3eb9957z3ZH0RdwVyk4o4ZGv379zB//+Efb0H/qqadsI1gNp2LFitnltIwaw2pI6f/KcLrvvvvsOCnqZhak8XrUgFaDQ+P1qHEXDGIpCKFy1bhREE5Br2+++Sa9LDW6NCaRMpH+/Oc/2waZjm+nTp3s+A1qwMn27dtt0E0ZIv5yCgbl9HjrXAXpKXl2uqupQansLGVsaZu0H3LOOefkaD98CtZonTqufle9W265xTYaVbfU6NSx/eijj8xXX31lGjRoEHfbFi1aZP8fbxll3xw4cMDcdNNNtuGtBmIYx10BVpWTFZ37smXLRrynAJbGfFK91DYqo0DdCz/99NP07DRtsxrtCtYMGTLErufZZ5+1gUP9fpMmTexyCjyo66Su8/POO8/W26VLl9rAlxrAsSgbzl9ex0kU4Irl6quvtvcTBR8VhPRt3rzZBo+C18iIESPMvffeazMltH4FI5QFqACnrrty5cqZ3ND9SteWgtE65hrTS0G1VatWRVyDubVjxw7TtGnT9GCa6qrus9dff709ngos+nbt2pWtdSrQonMbpPHDdP0pi0TBDwUWVZ7qQvDc9OnTx7Rp08aO06QsPl2LCsLpGPrBGGVc6tyoG63OvwLR2l7V8Wg6Xgqu655+6NAhM23aNNOtWzfz1ltv2WCQK3VC9wFda7o/R99DAAC54AEA8mzPnj2ebqkdO3bM1vKDBg2yyy9fvjzuMsuWLbPL3HnnnenvVa1a1WvXrp39d79+/bwSJUp4W7dutT/PmzfPLj99+vT05Q8fPuxVqlTJO//88yPWPWHCBLvse++9F7f8OnXqeC1atPDCovIHDBgQ9/MFCxbYZaZOnRrx/rvvvpvh/X379mX4/ZtvvtkrVaqUd+DAgfT3tD/6Xe1/0MaNG+37FSpU8Hbv3p3+/qxZs+z7c+bMSX+vVatWXt26dSPWe+TIEe+CCy7watSokeEcL168OP29nTt3emXLlrXvq8zM3H///Xa56JfqQPB86/++Pn36pH8u33//vV1G64qW3f2YPHmyXUfz5s1tfQrSvmR2DuMZNmyYXecvv/wS8zwce+yx9ljlZntzctx1vGId4+hX9HXgv7906dL09zZv3myvx86dO6e/16lTJ6948eLehg0b0t/T9XrMMcd4F110Ufp79erVS7+us6oPQaVLl7b7EM0/Z/6+6v509NFHe3fddVfEcqNGjfLS0tLstsumTZu8IkWKeCNGjIhYbtWqVV7RokUzvJ8d/jktWbKkt2XLlvT3dX70/h133BF3H/3f1f5Ei67X119/vb3X7dq1K2K5Hj162HMfvEdk55xHl+sf09atW9t659P265j99NNP9mfV6XLlynk33nhjxHZs377dbkfwfdXnU045JeI6mD9/fsR1Hu8ed+jQIe/ss8/2LrnkEufqRM2aNb0rrrgiw/sAgJxzJ+8dAAowPcH1n8hmhz9zU2bL+5/56441CKmyCJRlE4+yMZRJ8vHHH0dM56pMEj3VVvcMV6mrgLIalGGgJ+L+S2n5yqJR9pEvmD2hY6vllNmgJ9vqRhOkJ+bK2In31DmYvaJ1iDJs/GwXZe/oSbNfjl7KLNHT9PXr19tuGfLPf/7TPvHX026fnvoHxwzKDmWPqHuB/1I3nLzKyX74brzxxgxjYOjJ+uLFi7McADuaytF4LPHGuOjSpUt6d64wj7uyXoLHNt4r1iCq6jaiuujTwOIdO3a0mWvKntPr/ffftxlAwa4n6i557bXX2kwk/9rWcVQ2jvYjDMrwUVaZMpL+F6/4H2WF6Fhp2+WNN96wXcd0nIPXnAZFV3et4DWXUzoOwcwRnR9lGOl85ZX2SdeJBnrXv4PbrvqxZ8+eiG562Tnneul3oylzJdg1TfcInWtlpvjr/umnn2z2YnA7dO1of/1jqGtG2UXKcgleB+oqpoybaMF7nDJxtE8qO6vuh/lRJ3QPzW4WEwAgc3SJAoAE0JdfyWwK7VjBmMyWzyqoo0agZv5Qdw91/YhHDVWNHaEgjcZr0Zg4CxYssF05EjkIpbqiBCnYkpfuVmq8qlGicVFiCY7Lo8auAlhq1EcHuLSOIDUa4w1g6zdSfH7wxh8zRwNHq3Gj7gF6xdsulaEGnN/lJUhjnuSEuh3EG3Q4t3KyH77TTjstwzLqMqauHxr7SMGLtm3b2gZovLExsiu6rLCOu7pv6JUbaqxGq1mzpg0S+mOa6N+xyq1du7ZtBGsMEI2z8te//tUGe/T76k6lrlW6tv3ua4mgYKRmD1LwVt02N2zYYMdyUpee4DWn4xxr38TvFpjI46WAQV7peCtIonuhXlndL6LHTsqJrO4RftBN3b0y+1vhB3g0tlk0vRcdiFHXJ43F9Pnnn5uDBw+mvx8MHrlSJ7R8XrYLAPD/CNgAQALoS7gGvM1qEM1gg0008Oq5554bcxl9Jpk1KDWWjcYt0DgJeoIdixrStWrVMq+++qoN2Oj/+kKd00yPrEQPtKxxSPwBL3NDDVoFa+JllPgZGGqo6am0zoEavhqzQQN4qsEzdOjQDIPNZhZEihfA8p9A++vS7F2xnr7Ha4C5Jjf7Eeu46am7nvJroFRlk2jcC9VFPZXX0/t4NHCqssMUlIwVkIwuK6zjrmBe9FTZsSjAp3F0wqKgnBrLGjxbx1GDjSvIOmHChAzjV+WWsk80yLYCJGqc6/8aYFzjoASPsxraGvsl1rWQ7Fl/4jX6owcT9+uHxqRSADGWYPArOrgcT6ygc3bvEbovKwslWnZn+gpSgF3j16ieaKwk3WsVKNE9VoF41+qEglfxAjwAgJwhYAMACaJZN/R0V08r1V0iM2rM6suvvtTHG3hYg3Tqy72etsej4IQaKRrINFZWgU/BGWUmKAikL/j6Mh0caDIRomcFUeZAXmjf/vWvf9mBZjMLsmiWJHWNUZBADRqfBihOND9zRI2lrJ7SazacWF1cNCV7fjd4c7IfWVHjUQMS66UsBg0krEFKMwvYKIDon6PsZJGEddw1a5sG5c6KAoLRs3HFKmPdunW2AewHE/XvWOWqm54axspM8ikgpK56emkwZNVlDUacWcAmJ1kMGnxZ9yh1NRwzZozt+qJgmwLNwWtOgQdlOCn7JZHiHa/o2ZBiZa8oKBvkZ6f4dLwV+FMgJzv1OdYsfrHkJujsD/KrYHNm26J66mePRYt+T929FIRWd7vgIMjaPtfqhAKxyhwLzj4IAMg9xrABgATReBj6AqwGlmYsiaYn6JrpQ9RQU8NMAQnNHhJNT9bVvUczhvhTKMejrkCaFljdU+Lxs2k0w49S6hOdXSNqnARf2W0UxaPsDTXAND13rEaB34jzn/oGx2HQLCp6Ep1oaoRphh8FyLZt25bh8+D0vuoepNlWNGtQ8PNEjEGTXQoYxGrw5mQ/4tG5ie5upvWqsRfsshGLH9DUTEj5edzzMoaNArPBbitqpCpD5rLLLrN1Ui/9W+8Fx4/SvUFBU80Y5HePUcAxOmtBGUNZHUfdb6LPbVZdYDR2ijJ4VqxYYX8O0kxi2m5NMR68nkQ/R29nTqjrTXBcJJ0fjX+UWWBPx0fdAaOnS4++trXNGvdIgY1YWY7R9TkvY9hkRb+j7R45cqS9L8fbFl0n6v6mwLwCdD7NHqaxbaL3T4GYYGaR6pSOqWt1YvXq1XYWsOzMlggAyBoZNgCQIHoSqYaYvvCqy5MyZ/SFXMEDTWOsp5jBp7Xq8qAn7cpM0NTdfiaNnqKqkaen+rEaivGybDLLFNDTUX2B1nolXsBGDSO/caSGhaZv1rgJoif+wQyWRFCD3V9/kBrn2n9Nr63pbhVkUuNXGRZ6Uq9jqeBX165d7X7pSby6QmhcHjVslLkU3bhIlPHjx9vGtgYG1UC8yv5QI1wNeI0PpEaPHwzQdui8KpPDn15aT9b97m5hU2aSutTpybmejiuLQ3VSr+zuRzzqzqRgos5BvXr1bJBBAUhNE5xVvVVZ2gYt379//3w77nkZw0bbr8Z5cFpvUcPWp7qthr+2W9e5MuYUdFIgJhhg1Taozqv7os6Rrgt/uvTMaHkdQ2VHKACg6zyzTDsFs5SJoq5lfpAj+l6ibb777rttQEDdLLW8MqHU7U0D7up3RRlHmj5d01srEygrCkDpOGiaee2/xklR1zidr8woAK6B1fX/Ro0a2fuTMnOiaRkNgKv9V/3QMdVg1Qqq6Rjp3768ZpVlRsEaBeE1BpGyzTTouzKAvv32WzuNtzIGn3rqKbusgjoau0jvKYCvrkT6THUrGMTRtN06x6rTGrBamWy6HnRMo+t0ftYJUX1XoDjedPQAgBzKxcxSAIBMrFu3zk7dWq1aNTulr6bwbdasmffkk09GTEksBw8e9MaOHes1bNjQTseqaagbNGjgjRs3zk7bGi04rXfQ+vXr7dSr0dN6B40fP95+ft555+V4Kul4U0PnRWbT6Q4fPjx9uYkTJ9rjo2mBdSw1Fe6QIUPSpzOXhQsXek2bNrXLVK5c2X6uKcujp73W9MyarjyaP33w6NGjY25n9L5rmubevXt7FStW9IoVK+adfPLJXvv27b3XX389YrmVK1faMjXds5bRfk2aNClH03prau5YsjOttyxatMgeP9XF6H3Jzn740wEvWbIkQ90dPHiwnZJa50X1V/9++umnvewYM2aMV6ZMmYjpijM7D9nd3rwe95xMST9lyhQ7pbimR65fv37EufAtW7bMa9Omjd1XXd8tW7a05yTooYcestelpoNWHa5Vq5adLjl4D4g1rfeaNWvs9OD6HX3mT+ccPYVzUM+ePdOnp45nxowZdhp3nVO9tD3a37Vr16Yvo6nutZ4JEyZkeqyC5/Sxxx7zqlSpYo/XhRde6K1YsSJi2Vj7qPqhKbs1JbbqWffu3e007bGuyx07dtjtVBmqH6onmg5e95C8incdxLoO/fd13rXdqofVq1f3+vbtGzEVvEybNs0eXx0TTdM9e/Zsr0uXLva9INVfv67pM22Pa3VCmjRp4l133XVZHk8AQPak6T85DfIAAADkhbpTKUtGmSbq+leQKItrwIAB6ZkShZEyYzSAucZbCY6rgrzTQPTKyokeF8x1yoRUVpGymuINpg8AyBnGsAEAAEmnGXjU6NfMUtEzecF96n6kgcwJ1uSexrjReFxB6mqm7n3qIlfQqFuaukgSrAGAxCHDBgAAIAfIsEEiaEwYjaejMcg03ozGNNOA8wpmavBkjfEDACjcGHQYAAAASDINlq5BgjVDkwZ51wDZGmBYmSoEawAAQoYNAAAAAACAYxjDBgAAAAAAwDEEbAAAAAAAABxDwAYAAAAAAMAxBGwAAAAAAAAcQ8AGAAAAAADAMQRsAAAAAAAAHEPABgAAAAAAwDEEbAAAAAAAABxDwAYAAAAAAMAxBGwAAAAAAAAcQ8AGAAAAAADAMQRsAAAAAAAAHEPABgAAAAAAwDEEbAAAAAAAABxDwAYAAAAAAMAxBGwAAAAAAAAcQ8AGAAAAAADAMQRsAAAAAAAAHJPvAZuLL77YDBo0KP3natWqmXHjxuXrNqHgoj4hkahPSDTqFBKJ+oREoj4hkahPSKSLC3F9SkrApm/fviYtLS3D6+uvvzZvvPGGGT58eNzf1XJvvvlmaNvmeZ657777TKVKlUzJkiVN69atzfr160MrD6ldn1T+ZZddZipUqGDL+vzzz0MrC6ldn3777TczdOhQU7duXVO6dGlTuXJl07t3b7N169ZQykPq1yl54IEHTK1atWydKl++vP2bt3jx4tDKQ2rXp6BbbrnFlldYvkAXVC7Xp1jbdvnll4dWHlK7PslXX31lrrzySlO2bFn7d69x48bm22+/DbVMpGZ9SouxXXqNHj3ahK2oSRLdcCdPnhzx3gknnGCKFCmSlPLV+ClWrFiG90eNGmWeeOIJ89JLL5nTTjvN3HvvvaZNmzZm9erVpkSJEknZNqROfdq7d69p3ry56d69u7nxxhuTsi1Izfq0b98+s2zZMntPqlevnvnxxx/NwIED7RePpUuXJmW7kFp1SmrWrGmeeuopc/rpp5v9+/ebsWPH2iCzvgxp++AmV+uTb+bMmeaTTz6xgWW4z+X6FL1tRx99dFK2CalXnzZs2GC/k19//fXmwQcfNMcee6z58ssvad85ztX6tG3btoif33nnHVu3unTpkjpdonTDrVixYsRLBz46vSlIqU7SuXNnG8Hyf5ZZs2aZBg0a2ItOXzx1IR4+fDj9cy3/zDPP2MaNIqojRoyImV2jJ0HDhg0zHTt2NOecc455+eWX7RPsZD2RQurUJ+nVq5fN2NJTaxQcLtYnPQ364IMPbPDvzDPPNE2bNrUN7c8++4ynQwWAi3VKrr32Wnt/0jrq1KljxowZY37++WezcuXKhB8DpH59ku+++87cfvvtZurUqZkGdeAOl+tT9LYpExBuc7U+3XPPPaZt27b24Xz9+vVN9erV7e+ceOKJCT8GSP36VDFqm7Teli1b2nWm/Bg2mVmyZIn9v6Jsimr5Py9YsMB2DdDTZmXCPPvss+bFF1/McICV+q0Tt2rVKtO/f/8M69+4caPZvn17RONajaQmTZqYjz/+OPT9Q2rVJxQu+VGf9uzZY/+wlCtXLoQ9QmGrU4cOHTITJ060f/eUxYXUkoz6dOTIEfugYvDgwTYAiNSVrPvT/PnzbYNaDypuvfVW88MPP4S8Z0jF+qR709tvv22zStVzQnVK7TseyKemJUn+/rRjxw5bv5RhkxReEvTp08crUqSIV7p06fRX165d7WctWrTwBg4cmL5s1apVvbFjx6b/rE2cOXNmxPpatWrljRw5MuK9V155xatUqVLE7w0aNCjT7Vq4cKFdbuvWrRHvd+vWzevevXsu9xaFtT4Fbdy40f7O8uXLc7WPSJ6CUJ9k//79XoMGDbxrr702x/uI5HK9Ts2ZM8duU1pamle5cmXv008/zfW+onDXJ63n0ksv9Y4cORKzfLjH5fr06quverNmzfJWrlxpy6ldu7bXuHFj7/Dhw3naZxS++rRt2za7XKlSpbwxY8bY7+MPP/yw/bs3f/78PO83Cld9ivboo4965cuXt9/NkyFpY9goZUjpRj6lHOXWihUrzMKFCyOiY7///rs5cOCAHfehVKlS9r1GjRrlcavhKuoTClN9Un9adY3S35XgdsJdLtcpbZsGRN+1a5d57rnnbN3SwMOkibvLxfqk7pmPP/64HWtLmX8oOFysT9KjR4/0f2vAfQ1VoG4syrpp1apVrrcRha8+KcNGNOTFHXfcYf997rnnmkWLFpkJEyaYFi1a5HobUfjqU7QXXnjB9OzZM2njISUtYKODfcYZZyRkXb/++qvtf3bVVVdl+Cx44LI6wep/5qc1aZYon37WRQ13uVifUHC5XJ/8YM3mzZvN3Llz7aB5cJ/LdcrfNr00NlKNGjXMpEmTzN13352Q7UXhqE9KNd+5c6c59dRTI74I33XXXXZ8wE2bNiVke1E46lMsGhvi+OOPt4OiE7Bxl4v1SfWmaNGi5qyzzop4v3bt2uajjz5KyLai8NSn6L99a9euNa+99ppJlqQFbHJLA9jpC0CQBg7SgcrrydSsUArafPjhh+kBGg2+qCeN6jeL1BNmfULhE3Z98oM169evN/PmzbPTxSO15cc9Sk8iDx48GMq6kbr1SWPXRA+wr7Ei9H6/fv3ytG64Kdn3py1bttgxbIIPVZE6wqxPxYsXt1N4a11B69atM1WrVs3TulG470+TJk0yDRs2TOrYf84HbDTKswIqzZo1s6NGa7R4zcLTvn17+1Sna9eu5qijjrIpT1988YV56KGHsr1upfBqtGn9jp4w+tN6a1rKTp06hbpfSL36JLt377Yz+GimMfH/UPgjiiO1hFmfFKzR76u7wVtvvWX/CGmQdDnuuOPslxGknjDr1N69e21asGZCUANIXaLGjx9vZ/np1q1bqPuF1KtPCiBHB5H1hVl/6zRgLFJPmPXJfxKuKXJVhzQl85AhQ2xDS4FApJ6wv5NrMPSrr77aXHTRRbabzbvvvmvmzJlju9gh9VQLuT75iR3Tp083jz32mEkmp2eJEh0QTW1bpUoVOyWb6MatBsz7779vo6dK6R47dmyuIqb6Y6DpKG+66Sa7Lv3B0AWdrD5pSK36NHv2bLvedu3apffH1s/qL4vUE2Z9UiNa9UlPGJUBqAa2/1IfbKSmMOuUpsVcs2aNbRBp5owOHTrYp9dK72WGn9QU9t88FC5h359WrlxpA8q6P2n2FT3F1v1JjS+knrDvT5r1R9+/Na23xkR6/vnnzYwZM0zz5s1D2BsUhr9306ZNs+NJXnPNNSaZ0jTycFJLBAAAAAAAQMHOsAEAAAAAAChsCNgAAAAAAAA4hoANAAAAAACAYwjYAAAAAAAAOIaADQAAAAAAgGMI2AAAAAAAADiGgA0AAAAAAIBjimZ3wXPv/me4W2KM2fHNJpMM6yf3C72MMqVKhl5GQTb5uFqhl9HmzpYmGS7ZeXnoZax5omPoZRRkG3f9EnoZx7/9N5MMi0e9HXoZrb9cGnoZBdktadVCL+PJZc+YZDi8ZUPoZZTscFvoZRRkhz6ZGXoZXVZUNMkwvdc5oZdRolTp0Mso6Bac3yz0MirNesckQ/Ei4T87PrVCmdDLKMh+fPbu0MuoPjM57aIp424OvYy2tU4KvYyC7A9J+A51185VJhmum7g49DI+vqd1lsuQYQMAAAAAAOAYAjYAAAAAAACOIWADAAAAAADgGAI2AAAAAAAAjiFgAwAAAAAA4BgCNgAAAAAAAI4hYAMAAAAAAOAYAjYAAAAAAACOIWADAAAAAADgGAI2AAAAAAAAjiFgAwAAAAAA4BgCNgAAAAAAAI4hYAMAAAAAAOAYAjYAAAAAAACOIWADAAAAAADgGAI2AAAAAAAAjiFgAwAAAAAA4BgCNgAAAAAAAI4hYAMAAAAAAOAYAjYAAAAAAACOIWADAAAAAADgGAI2AAAAAAAAjiFgAwAAAAAA4BgCNgAAAAAAAI4pmt0FFw9tHO6WGGNGVrzdJEOxg13CL6RUyfDLKMA6jugYehkHfvjZJMM3C2YloZTwj1dBdualA0MvY/8bA0wyND+xclLKQXx9Ny4LvYyX6l9gkuHiXueGXsYZHW4LvYyCbMz+s0Mv4+RbLjXJcKh4r9DLKNFveOhlFHRNnx4WehmLr2prkuGSvTVDL+PQ8hdCL6Mg++LSu0Iv4z9XFjPJMHru16GX0bbWSaGXUZBVLJHt8EKufX9NB5MMb15eLwmltM5yCTJsAAAAAAAAHEPABgAAAAAAwDEEbAAAAAAAABxDwAYAAAAAAMAxBGwAAAAAAAAcQ8AGAAAAAADAMQRsAAAAAAAAHEPABgAAAAAAwDEEbAAAAAAAABxDwAYAAAAAAMAxBGwAAAAAAAAcQ8AGAAAAAADAMQRsAAAAAAAAHEPABgAAAAAAwDEEbAAAAAAAABxDwAYAAAAAAMAxBGwAAAAAAAAcQ8AGAAAAAADAMQRsAAAAAAAAHEPABgAAAAAAwDEEbAAAAAAAABxDwAYAAAAAAMAxBGwAAAAAAAAcQ8AGAAAAAADAMQRsAAAAAAAAHJPmeZ6XnQWL1+8f+sasfm+cSYa5Z54Xehk3/bgm9DIKsnKX3R96GXN++ZdJhoUjXwy9jD+3rBF6GQXZV9t/Dr2MJtc8bJLhpSf/GHoZnc+uFHoZBdnB+VNCL6PXxpomGV4+eWXoZZS47IbQyyjIjm//SOhlbBl0kkmGKd0eDb2MG/j+lKUXlnwbehlVypYwydCh572hl3FgybOhl1GQJaON9+v7D5hk2HTfnaGXUfOZ10MvoyBLRn3q//lckwz3/PBF6GVUOa5MlsuQYQMAAAAAAOAYAjYAAAAAAACOIWADAAAAAADgGAI2AAAAAAAAjiFgAwAAAAAA4BgCNgAAAAAAAI4hYAMAAAAAAOAYAjYAAAAAAACOIWADAAAAAADgGAI2AAAAAAAAjiFgAwAAAAAA4BgCNgAAAAAAAI4hYAMAAAAAAOAYAjYAAAAAAACOIWADAAAAAADgGAI2AAAAAAAAjiFgAwAAAAAA4BgCNgAAAAAAAI4hYAMAAAAAAOAYAjYAAAAAAACOIWADAAAAAADgGAI2AAAAAAAAjiFgAwAAAAAA4BgCNgAAAAAAAI5J8zzPy++NAAAAAAAAwP8jwwYAAAAAAMAxBGwAAAAAAAAcQ8AGAAAAAADAMQRsAAAAAAAAHEPABgAAAAAAwDEEbAAAAAAAABxDwAYAAAAAAMAxBGwAAAAAAAAcQ8AGAAAAAADAuOX/ANbhwqkjixJOAAAAAElFTkSuQmCC"
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "CONV2 - Filter Weights\n",
      "============================================================\n",
      "Shape: (3, 3, 8, 8) (height, width, in_channels, filters)\n",
      "\n",
      "Raw weight values for Filter 0, Channel 0:\n",
      "[[ 0.02112362  0.08767417  0.142784  ]\n",
      " [-0.07597622 -0.03746541 -0.16588247]\n",
      " [-0.14525884 -0.20131359 -0.04496397]]\n",
      "\n",
      "Min: -0.2013, Max: 0.1428\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1200 with 64 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2: Visualize Feature Maps (Filter Activations on Real Images)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-29T13:54:02.136105Z",
     "start_time": "2025-10-29T13:54:02.046469Z"
    }
   },
   "source": [
    "def visualize_feature_maps(model, image, label, class_names):\n",
    "    \"\"\"\n",
    "    Visualize what each filter \"sees\" when processing a real image.\n",
    "    \"\"\"\n",
    "    # Create models that output intermediate layer activations\n",
    "    conv1_model = keras.Model(inputs=model.input, outputs=model.get_layer('conv1').output)\n",
    "    conv2_model = keras.Model(inputs=model.input, outputs=model.get_layer('conv2').output)\n",
    "    \n",
    "    # Get predictions\n",
    "    image_batch = np.expand_dims(image, axis=0)  # Add batch dimension\n",
    "    predictions = model.predict(image_batch, verbose=0)\n",
    "    prediction = np.argmax(predictions[0])\n",
    "    \n",
    "    # Get activations\n",
    "    conv1_acts = conv1_model.predict(image_batch, verbose=0)[0]  # Shape: (28, 28, 8)\n",
    "    conv2_acts = conv2_model.predict(image_batch, verbose=0)[0]  # Shape: (14, 14, 8)\n",
    "    \n",
    "    # Display original image\n",
    "    input_img = image[:, :, 0]\n",
    "    \n",
    "    print(f\"\\nTrue Label: {class_names[label]} | Prediction: {class_names[prediction]}\")\n",
    "    \n",
    "    # Plot Conv1 activations\n",
    "    fig, axes = plt.subplots(2, 5, figsize=(15, 6))\n",
    "    \n",
    "    # Original image\n",
    "    axes[0, 0].imshow(input_img, cmap='gray')\n",
    "    axes[0, 0].set_title('Original Image')\n",
    "    axes[0, 0].axis('off')\n",
    "    \n",
    "    # Conv1 feature maps\n",
    "    for i in range(8):\n",
    "        row = (i + 1) // 5\n",
    "        col = (i + 1) % 5\n",
    "        axes[row, col].imshow(conv1_acts[:, :, i], cmap='viridis')\n",
    "        axes[row, col].set_title(f'Conv1 Filter {i}')\n",
    "        axes[row, col].axis('off')\n",
    "    \n",
    "    # Hide unused subplot\n",
    "    axes[1, 4].axis('off')\n",
    "    \n",
    "    plt.suptitle('Conv Layer 1 - Feature Maps (what each filter responds to)', fontsize=12)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Plot Conv2 activations\n",
    "    fig, axes = plt.subplots(2, 4, figsize=(12, 6))\n",
    "    for i in range(8):\n",
    "        row = i // 4\n",
    "        col = i % 4\n",
    "        axes[row, col].imshow(conv2_acts[:, :, i], cmap='viridis')\n",
    "        axes[row, col].set_title(f'Conv2 Filter {i}')\n",
    "        axes[row, col].axis('off')\n",
    "    \n",
    "    plt.suptitle('Conv Layer 2 - Feature Maps (higher-level features)', fontsize=12)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print some activation statistics\n",
    "    print(\"\\nActivation statistics for Conv1 Filter 0:\")\n",
    "    print(f\"Shape: {conv1_acts[:, :, 0].shape}\")\n",
    "    print(f\"Min: {conv1_acts[:, :, 0].min():.4f}, Max: {conv1_acts[:, :, 0].max():.4f}\")\n",
    "    print(f\"Mean: {conv1_acts[:, :, 0].mean():.4f}, Std: {conv1_acts[:, :, 0].std():.4f}\")\n",
    "\n",
    "# Get a sample image from test set\n",
    "sample_idx = 0  # Change this to see different examples\n",
    "sample_image = x_test[sample_idx]\n",
    "sample_label = y_test[sample_idx]\n",
    "\n",
    "visualize_feature_maps(model, sample_image, sample_label, CLASS_NAMES)"
   ],
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "The layer sequential has never been called and thus has no defined input.",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mAttributeError\u001B[39m                            Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[7]\u001B[39m\u001B[32m, line 70\u001B[39m\n\u001B[32m     67\u001B[39m sample_image = x_test[sample_idx]\n\u001B[32m     68\u001B[39m sample_label = y_test[sample_idx]\n\u001B[32m---> \u001B[39m\u001B[32m70\u001B[39m \u001B[43mvisualize_feature_maps\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msample_image\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msample_label\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mCLASS_NAMES\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[7]\u001B[39m\u001B[32m, line 6\u001B[39m, in \u001B[36mvisualize_feature_maps\u001B[39m\u001B[34m(model, image, label, class_names)\u001B[39m\n\u001B[32m      2\u001B[39m \u001B[38;5;250m\u001B[39m\u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m      3\u001B[39m \u001B[33;03mVisualize what each filter \"sees\" when processing a real image.\u001B[39;00m\n\u001B[32m      4\u001B[39m \u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m      5\u001B[39m \u001B[38;5;66;03m# Create models that output intermediate layer activations\u001B[39;00m\n\u001B[32m----> \u001B[39m\u001B[32m6\u001B[39m conv1_model = keras.Model(inputs=\u001B[43mmodel\u001B[49m\u001B[43m.\u001B[49m\u001B[43minput\u001B[49m, outputs=model.get_layer(\u001B[33m'\u001B[39m\u001B[33mconv1\u001B[39m\u001B[33m'\u001B[39m).output)\n\u001B[32m      7\u001B[39m conv2_model = keras.Model(inputs=model.input, outputs=model.get_layer(\u001B[33m'\u001B[39m\u001B[33mconv2\u001B[39m\u001B[33m'\u001B[39m).output)\n\u001B[32m      9\u001B[39m \u001B[38;5;66;03m# Get predictions\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/repos/classes/CST463-golden/.venv/lib/python3.12/site-packages/keras/src/ops/operation.py:275\u001B[39m, in \u001B[36mOperation.input\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m    265\u001B[39m \u001B[38;5;129m@property\u001B[39m\n\u001B[32m    266\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34minput\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[32m    267\u001B[39m \u001B[38;5;250m    \u001B[39m\u001B[33;03m\"\"\"Retrieves the input tensor(s) of a symbolic operation.\u001B[39;00m\n\u001B[32m    268\u001B[39m \n\u001B[32m    269\u001B[39m \u001B[33;03m    Only returns the tensor(s) corresponding to the *first time*\u001B[39;00m\n\u001B[32m   (...)\u001B[39m\u001B[32m    273\u001B[39m \u001B[33;03m        Input tensor or list of input tensors.\u001B[39;00m\n\u001B[32m    274\u001B[39m \u001B[33;03m    \"\"\"\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m275\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_get_node_attribute_at_index\u001B[49m\u001B[43m(\u001B[49m\u001B[32;43m0\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43minput_tensors\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43minput\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/repos/classes/CST463-golden/.venv/lib/python3.12/site-packages/keras/src/ops/operation.py:306\u001B[39m, in \u001B[36mOperation._get_node_attribute_at_index\u001B[39m\u001B[34m(self, node_index, attr, attr_name)\u001B[39m\n\u001B[32m    290\u001B[39m \u001B[38;5;250m\u001B[39m\u001B[33;03m\"\"\"Private utility to retrieves an attribute (e.g. inputs) from a node.\u001B[39;00m\n\u001B[32m    291\u001B[39m \n\u001B[32m    292\u001B[39m \u001B[33;03mThis is used to implement the properties:\u001B[39;00m\n\u001B[32m   (...)\u001B[39m\u001B[32m    303\u001B[39m \u001B[33;03m    The operation's attribute `attr` at the node of index `node_index`.\u001B[39;00m\n\u001B[32m    304\u001B[39m \u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m    305\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m._inbound_nodes:\n\u001B[32m--> \u001B[39m\u001B[32m306\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mAttributeError\u001B[39;00m(\n\u001B[32m    307\u001B[39m         \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mThe layer \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m.name\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m has never been called \u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    308\u001B[39m         \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mand thus has no defined \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mattr_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m.\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    309\u001B[39m     )\n\u001B[32m    310\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m._inbound_nodes) > node_index:\n\u001B[32m    311\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[32m    312\u001B[39m         \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mAsked to get \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mattr_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m at node \u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    313\u001B[39m         \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mnode_index\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m, but the operation has only \u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    314\u001B[39m         \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m._inbound_nodes)\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m inbound nodes.\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    315\u001B[39m     )\n",
      "\u001B[31mAttributeError\u001B[39m: The layer sequential has never been called and thus has no defined input."
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try different sample images to see how filters respond differently:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Visualize multiple examples\n",
    "for idx in [0, 10, 100, 500]:  # Different samples\n",
    "    sample_image = x_test[idx]\n",
    "    sample_label = y_test[idx]\n",
    "    visualize_feature_maps(model, sample_image, sample_label, CLASS_NAMES)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Method 2: Activation Maximization\n",
    "\n",
    "Instead of showing what filters respond to on real images, we can **generate** images that maximally activate specific filters. This helps us understand what pattern the filter is \"looking for.\"\n",
    "\n",
    "We start with random noise and use gradient ascent to modify the input to maximize the activation of a chosen filter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def activation_maximization(model, layer_name, filter_idx, iterations=100, lr=1.0):\n",
    "    \"\"\"\n",
    "    Generate an input image that maximally activates a specific filter.\n",
    "    \n",
    "    Args:\n",
    "        model: The CNN model\n",
    "        layer_name: Which layer to maximize ('conv1' or 'conv2')\n",
    "        filter_idx: Which filter in that layer to maximize\n",
    "        iterations: Number of optimization steps\n",
    "        lr: Learning rate for gradient ascent\n",
    "    \"\"\"\n",
    "    # Create a model that outputs the target layer's activations\n",
    "    layer_output = model.get_layer(layer_name).output\n",
    "    feature_extractor = keras.Model(inputs=model.input, outputs=layer_output)\n",
    "    \n",
    "    # Start with random noise\n",
    "    input_img = tf.Variable(tf.random.normal((1, 28, 28, 1)))\n",
    "    \n",
    "    # Track loss over iterations\n",
    "    losses = []\n",
    "    \n",
    "    for i in range(iterations):\n",
    "        with tf.GradientTape() as tape:\n",
    "            # Forward pass\n",
    "            activation = feature_extractor(input_img)\n",
    "            \n",
    "            # Get the activation of the target filter\n",
    "            # Shape: (1, height, width, num_filters)\n",
    "            filter_activation = activation[:, :, :, filter_idx]\n",
    "            \n",
    "            # We want to MAXIMIZE the mean activation\n",
    "            loss = -tf.reduce_mean(filter_activation)\n",
    "        \n",
    "        losses.append(-loss.numpy())  # Store positive value for plotting\n",
    "        \n",
    "        # Get gradients\n",
    "        grads = tape.gradient(loss, input_img)\n",
    "        \n",
    "        # Gradient ascent step\n",
    "        input_img.assign_add(lr * grads)\n",
    "        \n",
    "        # Normalize to keep values reasonable\n",
    "        mean = tf.reduce_mean(input_img)\n",
    "        std = tf.math.reduce_std(input_img)\n",
    "        input_img.assign((input_img - mean) / (std + 1e-5))\n",
    "        \n",
    "        if (i + 1) % 20 == 0:\n",
    "            print(f\"Iteration {i+1}/{iterations}, Activation: {losses[-1]:.4f}\")\n",
    "    \n",
    "    # Visualize result\n",
    "    result_img = input_img[0, :, :, 0].numpy()\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 2, figsize=(10, 4))\n",
    "    \n",
    "    # Show generated image\n",
    "    axes[0].imshow(result_img, cmap='gray')\n",
    "    axes[0].set_title(f'Generated Image\\nMaximizes {layer_name.upper()} Filter {filter_idx}')\n",
    "    axes[0].axis('off')\n",
    "    \n",
    "    # Show optimization progress\n",
    "    axes[1].plot(losses)\n",
    "    axes[1].set_xlabel('Iteration')\n",
    "    axes[1].set_ylabel('Mean Activation')\n",
    "    axes[1].set_title('Optimization Progress')\n",
    "    axes[1].grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"\\nFinal activation: {losses[-1]:.4f}\")\n",
    "    print(f\"Image stats - Min: {result_img.min():.4f}, Max: {result_img.max():.4f}\")\n",
    "    \n",
    "    return result_img\n",
    "\n",
    "# Generate images that maximize different filters\n",
    "print(\"\\nGenerating images for Conv1 filters:\")\n",
    "for filter_idx in range(4):  # Show first 4 filters\n",
    "    print(f\"\\n--- Conv1 Filter {filter_idx} ---\")\n",
    "    activation_maximization(model, 'conv1', filter_idx, iterations=100, lr=1.0)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Try Conv2 filters (more abstract patterns)\n",
    "print(\"\\nGenerating images for Conv2 filters:\")\n",
    "for filter_idx in range(4):  # Show first 4 filters\n",
    "    print(f\"\\n--- Conv2 Filter {filter_idx} ---\")\n",
    "    activation_maximization(model, 'conv2', filter_idx, iterations=100, lr=1.0)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Method 3: Class Activation Maps (Grad-CAM)\n",
    "\n",
    "Grad-CAM shows which parts of the input image are most important for the network's prediction. It works by:\n",
    "1. Computing gradients of the predicted class with respect to feature maps\n",
    "2. Weighting feature maps by these gradients\n",
    "3. Creating a heatmap showing important regions\n",
    "\n",
    "This helps answer: \"What is the network looking at when it makes this prediction?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def grad_cam(model, image, target_class=None):\n",
    "    \"\"\"\n",
    "    Generate a Grad-CAM heatmap showing which image regions influence the prediction.\n",
    "    \n",
    "    Args:\n",
    "        model: The CNN model\n",
    "        image: Input image (28, 28, 1)\n",
    "        target_class: Class to generate CAM for (None = predicted class)\n",
    "    \"\"\"\n",
    "    # Prepare image\n",
    "    img_array = np.expand_dims(image, axis=0)\n",
    "    \n",
    "    # Create a model that outputs both the final predictions and conv2 activations\n",
    "    grad_model = keras.Model(\n",
    "        inputs=model.input,\n",
    "        outputs=[model.get_layer('conv2').output, model.output]\n",
    "    )\n",
    "    \n",
    "    # Get predictions\n",
    "    with tf.GradientTape() as tape:\n",
    "        conv_outputs, predictions = grad_model(img_array)\n",
    "        \n",
    "        # Get predicted class if not specified\n",
    "        if target_class is None:\n",
    "            target_class = tf.argmax(predictions[0]).numpy()\n",
    "        \n",
    "        # Get the score for the target class\n",
    "        class_channel = predictions[:, target_class]\n",
    "    \n",
    "    # Compute gradients of the class score with respect to conv2 output\n",
    "    grads = tape.gradient(class_channel, conv_outputs)\n",
    "    \n",
    "    # Global average pooling of gradients (importance weights)\n",
    "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))  # Shape: (8,)\n",
    "    \n",
    "    print(f\"\\nGrad-CAM weights for target class '{CLASS_NAMES[target_class]}':\")\n",
    "    print(f\"Shape: {pooled_grads.shape} (one weight per filter)\")\n",
    "    print(f\"Weights: {pooled_grads.numpy()}\")\n",
    "    print(f\"\\nInterpretation: Positive weights mean that filter's activation increases prediction confidence\")\n",
    "    \n",
    "    # Weighted combination of feature maps\n",
    "    conv_outputs = conv_outputs[0]  # Remove batch dimension\n",
    "    \n",
    "    # Multiply each filter by its weight and sum\n",
    "    cam = tf.reduce_sum(tf.multiply(pooled_grads, conv_outputs), axis=-1)\n",
    "    \n",
    "    # Apply ReLU (only positive influences)\n",
    "    cam = tf.nn.relu(cam)\n",
    "    \n",
    "    # Normalize\n",
    "    cam = cam - tf.reduce_min(cam)\n",
    "    cam = cam / (tf.reduce_max(cam) + 1e-8)\n",
    "    \n",
    "    # Resize to original image size\n",
    "    cam = tf.image.resize(cam[..., tf.newaxis], (28, 28))\n",
    "    cam = cam.numpy()[:, :, 0]\n",
    "    \n",
    "    return cam, target_class\n",
    "\n",
    "\n",
    "def visualize_grad_cam(model, image, label, class_names):\n",
    "    \"\"\"\n",
    "    Visualize Grad-CAM heatmap overlaid on original image.\n",
    "    \"\"\"\n",
    "    cam, predicted_class = grad_cam(model, image)\n",
    "    \n",
    "    # Get original image\n",
    "    orig_img = image[:, :, 0]\n",
    "    \n",
    "    # Create visualization\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "    \n",
    "    # Original image\n",
    "    axes[0].imshow(orig_img, cmap='gray')\n",
    "    axes[0].set_title(f'Original Image\\nTrue: {class_names[label]}')\n",
    "    axes[0].axis('off')\n",
    "    \n",
    "    # Heatmap\n",
    "    im = axes[1].imshow(cam, cmap='jet')\n",
    "    axes[1].set_title(f'Grad-CAM Heatmap\\nPredicted: {class_names[predicted_class]}')\n",
    "    axes[1].axis('off')\n",
    "    plt.colorbar(im, ax=axes[1], fraction=0.046)\n",
    "    \n",
    "    # Overlay\n",
    "    axes[2].imshow(orig_img, cmap='gray')\n",
    "    axes[2].imshow(cam, cmap='jet', alpha=0.5)  # Overlay with transparency\n",
    "    axes[2].set_title('Overlay\\n(red = important for prediction)')\n",
    "    axes[2].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"\\nCAM statistics:\")\n",
    "    print(f\"Min: {cam.min():.4f}, Max: {cam.max():.4f}\")\n",
    "    print(f\"Mean: {cam.mean():.4f}, Std: {cam.std():.4f}\")\n",
    "\n",
    "# Visualize Grad-CAM for several examples\n",
    "print(\"\\nGenerating Grad-CAM visualizations:\")\n",
    "for idx in [0, 10, 100, 500]:\n",
    "    sample_image = x_test[idx]\n",
    "    sample_label = y_test[idx]\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Sample {idx}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    visualize_grad_cam(model, sample_image, sample_label, CLASS_NAMES)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare Grad-CAM for Different Classes\n",
    "\n",
    "We can also generate Grad-CAM for a specific class (not necessarily the predicted one) to see what the network would look for if trying to classify the image as that class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def compare_class_cams(model, image, label, class_names, classes_to_compare=None):\n",
    "    \"\"\"\n",
    "    Compare Grad-CAM for different target classes on the same image.\n",
    "    \"\"\"\n",
    "    if classes_to_compare is None:\n",
    "        classes_to_compare = [label, (label + 1) % 10, (label + 2) % 10]\n",
    "    \n",
    "    orig_img = image[:, :, 0]\n",
    "    \n",
    "    fig, axes = plt.subplots(1, len(classes_to_compare) + 1, figsize=(4 * (len(classes_to_compare) + 1), 4))\n",
    "    \n",
    "    # Original image\n",
    "    axes[0].imshow(orig_img, cmap='gray')\n",
    "    axes[0].set_title(f'Original\\nTrue: {class_names[label]}')\n",
    "    axes[0].axis('off')\n",
    "    \n",
    "    # Generate CAM for each class\n",
    "    for i, target_class in enumerate(classes_to_compare):\n",
    "        cam, _ = grad_cam(model, image, target_class=target_class)\n",
    "        \n",
    "        axes[i + 1].imshow(orig_img, cmap='gray')\n",
    "        axes[i + 1].imshow(cam, cmap='jet', alpha=0.5)\n",
    "        axes[i + 1].set_title(f'CAM for\\n\"{class_names[target_class]}\"')\n",
    "        axes[i + 1].axis('off')\n",
    "    \n",
    "    plt.suptitle('Grad-CAM for Different Target Classes\\n(Shows what network looks for to classify as each class)', \n",
    "                 fontsize=12)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Example: see what features matter for different class predictions\n",
    "sample_image = x_test[0]\n",
    "sample_label = y_test[0]\n",
    "compare_class_cams(model, sample_image, sample_label, CLASS_NAMES)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Summary and Next Steps\n",
    "\n",
    "## What We've Learned\n",
    "\n",
    "1. **Filter Visualizations**: Convolutional filters learn edge detectors, texture patterns, and shape components\n",
    "   - Early layers (Conv1) detect simple patterns (edges, corners)\n",
    "   - Later layers (Conv2) detect more complex combinations\n",
    "\n",
    "2. **Activation Maximization**: We can synthesize images that maximally activate specific filters\n",
    "   - Shows what each filter is \"looking for\"\n",
    "   - Often reveals interesting patterns that aren't obvious from weights alone\n",
    "\n",
    "3. **Grad-CAM**: Highlights which image regions drive predictions\n",
    "   - Shows the model is (hopefully) looking at relevant features\n",
    "   - Can help debug incorrect predictions\n",
    "   - Different target classes focus on different regions\n",
    "\n",
    "## Experiments to Try\n",
    "\n",
    "1. **Switch datasets**: Change `DATASET = 'fashion_mnist'` and re-run to see how filters differ\n",
    "2. **Modify architecture**: Add more filters or layers and see how complexity affects learned features\n",
    "3. **Tune activation maximization**: Adjust learning rate and iterations for clearer generated images\n",
    "4. **Find failure cases**: Use Grad-CAM to understand misclassifications\n",
    "\n",
    "## Questions to Consider\n",
    "\n",
    "- Do Conv1 filters look similar across MNIST and Fashion-MNIST?\n",
    "- What happens to Grad-CAM when the model makes a wrong prediction?\n",
    "- Can you identify which filters are most important for specific digit/class recognition?\n",
    "- How do activation maximization results differ between Conv1 and Conv2 filters?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
