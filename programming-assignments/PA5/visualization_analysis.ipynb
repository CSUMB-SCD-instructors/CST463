{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PA5: Text Representation Learning - Visualization & Analysis\n",
    "\n",
    "**Part 2 (30 points)**\n",
    "\n",
    "In this notebook, you will analyze and compare the different text representation methods you implemented in Part 1:\n",
    "- Random/Pretrained Embeddings (baseline)\n",
    "- Autoencoder Embeddings\n",
    "- Word2Vec Embeddings\n",
    "- Attention-Based Embeddings\n",
    "\n",
    "**Important**: Use **matplotlib only** for all visualizations (no seaborn).\n",
    "\n",
    "**Grading Breakdown:**\n",
    "1. Embedding Space Visualization (8 points)\n",
    "2. Semantic Relationships (7 points)\n",
    "3. Attention Pattern Investigation (6 points)\n",
    "4. Classification Performance Analysis (5 points)\n",
    "5. Cross-Course Connections - Executive Summary (4 points)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "import student_code\n",
    "import utils\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# Suppress TensorFlow warnings\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "print(\"Libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Prepare Data\n",
    "\n",
    "Load the IMDB dataset using your implementation from Part 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "VOCAB_SIZE = 10000\n",
    "MAX_LENGTH = 200\n",
    "EMBEDDING_DIM = 128\n",
    "TRAIN_SIZE = 10000\n",
    "VAL_SIZE = 2500\n",
    "TEST_SIZE = 5000\n",
    "\n",
    "# Load data\n",
    "print(\"Loading IMDB dataset...\")\n",
    "(X_train, y_train), (X_val, y_val), (X_test, y_test) = student_code.load_and_preprocess_imdb(\n",
    "    vocab_size=VOCAB_SIZE,\n",
    "    max_length=MAX_LENGTH,\n",
    "    train_size=TRAIN_SIZE,\n",
    "    val_size=VAL_SIZE,\n",
    "    test_size=TEST_SIZE\n",
    ")\n",
    "\n",
    "# Create vocabulary mappings\n",
    "word_to_idx, idx_to_word = student_code.create_vocabulary_mappings(vocab_size=VOCAB_SIZE)\n",
    "\n",
    "# Print statistics\n",
    "utils.print_data_statistics(X_train, y_train, X_val, y_val, X_test, y_test)\n",
    "\n",
    "# Decode a sample review to verify\n",
    "print(\"\\nSample review:\")\n",
    "print(utils.decode_review(X_train[0]))\n",
    "print(f\"Label: {'Positive' if y_train[0] == 1 else 'Negative'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build and Train All Embedding Models\n",
    "\n",
    "Train all four embedding approaches so we can compare them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Random Baseline Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Building random embedding model...\")\n",
    "random_model = student_code.build_random_embedding_model(\n",
    "    vocab_size=VOCAB_SIZE,\n",
    "    embedding_dim=EMBEDDING_DIM,\n",
    "    max_length=MAX_LENGTH\n",
    ")\n",
    "\n",
    "print(\"Training random embedding model...\")\n",
    "random_history = random_model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=5,\n",
    "    batch_size=128,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(f\"Random embedding model trained. Final val accuracy: {random_history.history['val_accuracy'][-1]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Autoencoder Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Building autoencoder...\")\n",
    "autoencoder_encoder = student_code.build_autoencoder_encoder(\n",
    "    vocab_size=VOCAB_SIZE,\n",
    "    embedding_dim=EMBEDDING_DIM,\n",
    "    max_length=MAX_LENGTH\n",
    ")\n",
    "autoencoder_decoder = student_code.build_autoencoder_decoder(\n",
    "    vocab_size=VOCAB_SIZE,\n",
    "    embedding_dim=EMBEDDING_DIM\n",
    ")\n",
    "\n",
    "print(\"Training autoencoder...\")\n",
    "autoencoder_history = student_code.train_autoencoder(\n",
    "    autoencoder_encoder,\n",
    "    autoencoder_decoder,\n",
    "    X_train,\n",
    "    epochs=20,\n",
    "    batch_size=128\n",
    ")\n",
    "\n",
    "# Build classifier using autoencoder embeddings\n",
    "print(\"Building classifier with autoencoder embeddings...\")\n",
    "autoencoder_classifier = student_code.build_sentiment_classifier(\n",
    "    embedding_model=autoencoder_encoder,\n",
    "    max_length=MAX_LENGTH,\n",
    "    model_type='autoencoder'\n",
    ")\n",
    "\n",
    "# Train the classifier\n",
    "print(\"Training autoencoder classifier...\")\n",
    "# TODO: Train the autoencoder_classifier\n",
    "# autoencoder_clf_history = autoencoder_classifier.fit(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Word2Vec Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Generating skip-gram pairs...\")\n",
    "skipgram_pairs = student_code.generate_skipgram_pairs(\n",
    "    sequences=X_train,\n",
    "    window_size=2,\n",
    "    vocab_size=VOCAB_SIZE\n",
    ")\n",
    "print(f\"Generated {len(skipgram_pairs)} skip-gram pairs\")\n",
    "\n",
    "print(\"Building Word2Vec model...\")\n",
    "word2vec_model = student_code.build_word2vec_model(\n",
    "    vocab_size=VOCAB_SIZE,\n",
    "    embedding_dim=EMBEDDING_DIM\n",
    ")\n",
    "\n",
    "print(\"Training Word2Vec...\")\n",
    "word2vec_history = student_code.train_word2vec(\n",
    "    model=word2vec_model,\n",
    "    pairs=skipgram_pairs,\n",
    "    epochs=5,\n",
    "    batch_size=1024\n",
    ")\n",
    "\n",
    "# Build classifier using Word2Vec embeddings\n",
    "print(\"Building classifier with Word2Vec embeddings...\")\n",
    "# TODO: Extract Word2Vec embeddings and build classifier\n",
    "# word2vec_classifier = student_code.build_sentiment_classifier(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Attention-Based Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Building attention-based model...\")\n",
    "# TODO: Build a model that uses your SimpleAttention layer\n",
    "# attention_model = student_code.build_sentiment_classifier(\n",
    "#     embedding_model=...,\n",
    "#     max_length=MAX_LENGTH,\n",
    "#     model_type='attention'\n",
    "# )\n",
    "\n",
    "# TODO: Train the attention model\n",
    "# attention_history = attention_model.fit(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Analysis Section 1: Embedding Space Visualization (8 points)\n",
    "\n",
    "Visualize and compare the embedding spaces learned by different methods.\n",
    "\n",
    "**Tasks:**\n",
    "1. Extract embeddings for a set of semantically meaningful words\n",
    "2. Project embeddings to 2D using PCA (connects to PA1!)\n",
    "3. Create scatter plots comparing embedding spaces\n",
    "4. Analyze which method best captures semantic relationships\n",
    "\n",
    "**Remember:** Use matplotlib only, with proper labels and legends."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select words to visualize (mix of positive, negative, neutral)\n",
    "sample_words = [\n",
    "    # Positive sentiment\n",
    "    'excellent', 'amazing', 'wonderful', 'great', 'fantastic', 'love',\n",
    "    # Negative sentiment\n",
    "    'terrible', 'awful', 'horrible', 'bad', 'worst', 'hate',\n",
    "    # Neutral/common\n",
    "    'movie', 'film', 'story', 'actor', 'character', 'plot'\n",
    "]\n",
    "\n",
    "# TODO: Extract embeddings for these words from each model\n",
    "# Use student_code.extract_embeddings()\n",
    "\n",
    "# random_embeddings = ...\n",
    "# word2vec_embeddings = ...\n",
    "# autoencoder_embeddings = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Apply PCA to reduce embeddings to 2D\n",
    "# This connects to PA1 where you implemented PCA!\n",
    "\n",
    "# pca = PCA(n_components=2)\n",
    "# random_2d = pca.fit_transform(random_embeddings)\n",
    "# word2vec_2d = pca.fit_transform(word2vec_embeddings)\n",
    "# ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create visualization comparing embedding spaces\n",
    "# Create a figure with subplots for each embedding method\n",
    "# Use different colors for positive/negative/neutral words\n",
    "# Add word labels to points\n",
    "# Include proper titles, axis labels, and legend\n",
    "\n",
    "# Example structure:\n",
    "# fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "# # Plot each embedding method in a subplot\n",
    "# # Use scatter plots with color coding\n",
    "# # Add annotations for word labels\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis Questions (Embedding Space Visualization)\n",
    "\n",
    "Answer the following questions based on your visualizations:\n",
    "\n",
    "**Q1.1:** Which embedding method shows the clearest separation between positive and negative sentiment words? Provide evidence from your visualization.\n",
    "\n",
    "*Your answer here*\n",
    "\n",
    "**Q1.2:** How does the random baseline compare to the learned embeddings? What does this tell you about the importance of training embeddings?\n",
    "\n",
    "*Your answer here*\n",
    "\n",
    "**Q1.3:** Are semantically related words (e.g., 'movie' and 'film') close together in the embedding spaces? How does this differ across methods?\n",
    "\n",
    "*Your answer here*\n",
    "\n",
    "**Q1.4:** Connect to PA1: How is PCA being used here similar to how you used it in PA1? How is the autoencoder's embedding similar to PCA?\n",
    "\n",
    "*Your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Analysis Section 2: Semantic Relationships (7 points)\n",
    "\n",
    "Investigate whether embeddings capture semantic relationships between words.\n",
    "\n",
    "**Tasks:**\n",
    "1. Find nearest neighbors for key words in embedding space\n",
    "2. Test word analogies (if applicable)\n",
    "3. Compare semantic quality across methods\n",
    "4. Visualize similarity matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement nearest neighbor search\n",
    "# For a given word, find the k most similar words based on cosine similarity\n",
    "\n",
    "def find_nearest_neighbors(word, embeddings, word_to_idx, idx_to_word, k=5):\n",
    "    \"\"\"\n",
    "    Find k nearest neighbors to a word in embedding space.\n",
    "    \n",
    "    Use cosine similarity: similarity = (a Â· b) / (||a|| ||b||)\n",
    "    \"\"\"\n",
    "    # TODO: Implement this function\n",
    "    pass\n",
    "\n",
    "# Test nearest neighbors for key words\n",
    "test_words = ['excellent', 'terrible', 'movie', 'actor']\n",
    "\n",
    "# TODO: Find and print nearest neighbors for each test word in each embedding space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create similarity matrix visualization\n",
    "# Compute pairwise cosine similarities between sample words\n",
    "# Visualize as heatmaps for each embedding method\n",
    "\n",
    "# Example:\n",
    "# fig, axes = plt.subplots(2, 2, figsize=(16, 14))\n",
    "# # For each embedding method:\n",
    "# #   1. Compute pairwise similarities\n",
    "# #   2. Create heatmap with plt.imshow()\n",
    "# #   3. Add colorbar and word labels\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis Questions (Semantic Relationships)\n",
    "\n",
    "**Q2.1:** Which embedding method produces the most semantically meaningful nearest neighbors? Provide specific examples.\n",
    "\n",
    "*Your answer here*\n",
    "\n",
    "**Q2.2:** Do the similarity matrices show expected patterns (e.g., positive words similar to each other, dissimilar to negative words)? Which method performs best?\n",
    "\n",
    "*Your answer here*\n",
    "\n",
    "**Q2.3:** Why might Word2Vec capture different relationships than the autoencoder? Think about what each method optimizes for.\n",
    "\n",
    "*Your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Analysis Section 3: Attention Pattern Investigation (6 points)\n",
    "\n",
    "Analyze what your attention mechanism has learned.\n",
    "\n",
    "**Tasks:**\n",
    "1. Extract attention weights for sample reviews\n",
    "2. Visualize which words receive high attention\n",
    "3. Determine if attention focuses on sentiment-bearing words\n",
    "4. Compare to simple averaging baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Extract attention weights from your SimpleAttention layer\n",
    "# You may need to modify your SimpleAttention layer to return both\n",
    "# the attended output and the attention weights\n",
    "\n",
    "def get_attention_weights(model, sequences):\n",
    "    \"\"\"\n",
    "    Extract attention weights for input sequences.\n",
    "    \n",
    "    Returns:\n",
    "        weights: shape (n_samples, sequence_length)\n",
    "    \"\"\"\n",
    "    # TODO: Implement this function\n",
    "    pass\n",
    "\n",
    "# Select sample reviews (some positive, some negative)\n",
    "sample_indices = [0, 1, 10, 11, 100, 101]  # Adjust as needed\n",
    "sample_reviews = X_test[sample_indices]\n",
    "sample_labels = y_test[sample_indices]\n",
    "\n",
    "# TODO: Get attention weights for these reviews\n",
    "# attention_weights = get_attention_weights(attention_model, sample_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Visualize attention weights\n",
    "# Create heatmaps showing attention weights for each review\n",
    "# Overlay the actual words to see what gets attended to\n",
    "\n",
    "# Example visualization:\n",
    "# for i, (review, weights, label) in enumerate(zip(sample_reviews, attention_weights, sample_labels)):\n",
    "#     # Decode review to words\n",
    "#     words = utils.decode_review(review).split()\n",
    "#     # Create bar plot of attention weights per word\n",
    "#     # Highlight high-attention words\n",
    "#     # Add title indicating true label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis Questions (Attention Patterns)\n",
    "\n",
    "**Q3.1:** Does your attention mechanism focus on words that are intuitively important for sentiment? Provide specific examples.\n",
    "\n",
    "*Your answer here*\n",
    "\n",
    "**Q3.2:** Are there differences in attention patterns between positive and negative reviews?\n",
    "\n",
    "*Your answer here*\n",
    "\n",
    "**Q3.3:** How does attention compare to simply averaging all word embeddings (like GlobalAveragePooling)? What's the advantage of learning attention weights?\n",
    "\n",
    "*Your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Analysis Section 4: Classification Performance Analysis (5 points)\n",
    "\n",
    "Compare the downstream task performance of different embeddings.\n",
    "\n",
    "**Tasks:**\n",
    "1. Evaluate all models on test set\n",
    "2. Compare accuracy, loss, and training dynamics\n",
    "3. Analyze which embeddings work best for sentiment classification\n",
    "4. Investigate failure cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Evaluate all models on test set\n",
    "models_dict = {\n",
    "    'Random': random_model,\n",
    "    'Autoencoder': autoencoder_classifier,\n",
    "    # 'Word2Vec': word2vec_classifier,\n",
    "    # 'Attention': attention_model,\n",
    "}\n",
    "\n",
    "# Use your evaluate_all_embeddings function\n",
    "# results = student_code.evaluate_all_embeddings(models_dict, X_test, y_test)\n",
    "\n",
    "# TODO: Print and visualize results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Visualize training dynamics\n",
    "# Plot training and validation accuracy/loss curves for each model\n",
    "# Compare convergence speed and overfitting\n",
    "\n",
    "# Example:\n",
    "# fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "# # Left plot: Accuracy curves\n",
    "# # Right plot: Loss curves\n",
    "# # Include all models for comparison\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Error analysis\n",
    "# Find examples that all models get wrong\n",
    "# Find examples where embeddings disagree\n",
    "# Analyze what makes these reviews difficult\n",
    "\n",
    "# Example:\n",
    "# predictions = {name: model.predict(X_test) for name, model in models_dict.items()}\n",
    "# # Find misclassified examples\n",
    "# # Print/analyze difficult reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis Questions (Classification Performance)\n",
    "\n",
    "**Q4.1:** Which embedding method achieves the best test accuracy? Does this match your expectations based on the embedding quality visualizations?\n",
    "\n",
    "*Your answer here*\n",
    "\n",
    "**Q4.2:** Compare training dynamics. Which method converges fastest? Which shows most/least overfitting?\n",
    "\n",
    "*Your answer here*\n",
    "\n",
    "**Q4.3:** Based on error analysis, what types of reviews are difficult for all models? Why might this be?\n",
    "\n",
    "*Your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Analysis Section 5: Cross-Course Connections - Executive Summary (4 points)\n",
    "\n",
    "Synthesize your findings and connect to broader themes from the course.\n",
    "\n",
    "**This section should be written for a peer audience (peer review preparation).**\n",
    "\n",
    "### Executive Summary\n",
    "\n",
    "Write a 2-3 paragraph executive summary addressing:\n",
    "1. **Main findings**: Which embedding method(s) worked best and why?\n",
    "2. **Connections to course concepts**: How do these embeddings relate to other representation learning you've seen (PCA from PA1, CNN filters from PA4, etc.)?\n",
    "3. **Practical implications**: When would you choose each embedding approach in real applications?\n",
    "\n",
    "*Your executive summary here (2-3 paragraphs)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conceptual Connection Questions\n",
    "\n",
    "**Q5.1:** How are word embeddings similar to CNN filters (PA4)? How are they different?\n",
    "\n",
    "*Your answer here*\n",
    "\n",
    "**Q5.2:** The autoencoder learns embeddings through reconstruction loss. How is this conceptually similar to PCA (PA1)? How does it differ?\n",
    "\n",
    "*Your answer here*\n",
    "\n",
    "**Q5.3:** Word2Vec learns embeddings by predicting context. Attention learns to weight words by importance. How do these different objectives lead to different embedding properties?\n",
    "\n",
    "*Your answer here*\n",
    "\n",
    "**Q5.4:** What is the unifying theme across all these methods (embeddings, CNN filters, PCA, autoencoders)? What fundamental problem are they all trying to solve?\n",
    "\n",
    "*Your answer here (this is the key insight!)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Peer Review Preparation\n",
    "\n",
    "### Question for Peer Reviewers\n",
    "\n",
    "Write 1-2 specific questions you'd like your peer reviewers to focus on when evaluating your work:\n",
    "\n",
    "1. *Your question 1*\n",
    "2. *Your question 2*\n",
    "\n",
    "### Challenges and Insights\n",
    "\n",
    "Reflect on:\n",
    "- What was most challenging about this assignment?\n",
    "- What was your most important insight or \"aha moment\"?\n",
    "- How has this changed your understanding of representation learning?\n",
    "\n",
    "*Your reflection here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Submission Checklist\n",
    "\n",
    "Before submitting, ensure you have:\n",
    "\n",
    "- [ ] Completed all code cells with proper implementations\n",
    "- [ ] Created all required visualizations using matplotlib only\n",
    "- [ ] All plots have proper titles, axis labels, and legends\n",
    "- [ ] Answered all analysis questions with evidence-based reasoning\n",
    "- [ ] Written executive summary for peer audience\n",
    "- [ ] Provided questions for peer reviewers\n",
    "- [ ] Run all cells and verified output\n",
    "- [ ] Notebook runs from top to bottom without errors\n",
    "\n",
    "**Note**: Your analysis will be evaluated on the quality of reasoning and depth of insights, NOT on achieving specific numerical results. Focus on clear communication and evidence-based conclusions."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
